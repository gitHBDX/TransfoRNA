{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforna import GeneEmbeddModel,load,Results_Handler,RnaTokenizer\n",
    "import yaml\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "mapping_dict_path: str = '/media/ftp_share/hbdx/data_for_upload/TransfoRNA/data/subclass_to_annotation.json'\n",
    "model = \"Seq-Rev\"\n",
    "model_name = f\"Yak-hbdx/{model}-TransfoRNA\"\n",
    "model_dir = f\"/nfs/home/yat_ldap/VS_Projects/TransfoRNA-Framework/models/tcga/TransfoRNA_FULL/sub_class/{model}/\"\n",
    "model_path = model_dir+\"/ckpt/model_params_tcga.pt\"\n",
    "model_config_path = model_dir+\"meta/hp_settings.yaml\"\n",
    "knn_path = model_dir+\"/post_models/knn_model.sav\"\n",
    "cfg = load(model_config_path)\n",
    "mapping_dict = load(mapping_dict_path)\n",
    "#results_handler = Results_Handler(embedds_path = model_dir+\"embedds\",splits=['train'])\n",
    "#results_handler.get_knn_model()\n",
    "with open(model_dir+\"/seq_tokens_ids_dict.yaml\") as file:\n",
    "    token_to_ids = yaml.load(file, Loader=yaml.FullLoader)\n",
    "if 'struct' in model.lower():\n",
    "    with open(model_dir+\"/second_input_tokens_ids_dict.yaml\") as file:\n",
    "        second_input_token_to_ids = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "    token_to_ids.update(second_input_token_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg[\"train_config\"][\"device\"] = 'cpu'\n",
    "cfg[\"mapping_dict\"] = mapping_dict\n",
    "#cfg[\"results_handler\"] = results_handler\n",
    "model = GeneEmbeddModel(cfg)\n",
    "#load state dict\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.push_to_hub(model_name)\n",
    "model = GeneEmbeddModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing sequences for yak-hbdx/seq-rev-transforna model...\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RnaTokenizer(model_max_length=29,model_name=model_name)\n",
    "tokenizer.add_special_tokens({'pad_token': 'pad'})\n",
    "x = tokenizer(['AACGAAGCTCGACTTTTAAGG'\\\n",
    "            ,'GTCCACCCCAAAGCGTAGG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 8,  4, 16,  3,  8, 10, 11,  1, 12, 16,  3,  4,  1,  9,  9,  9,  6,  8,\n",
       "         10, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0, 15, 10,  8,  6,  9,  9,  9,\n",
       "          1,  4,  3, 16, 12,  1, 11, 10,  8,  3, 16,  4,  8,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0, 21],\n",
       "        [14, 12,  5, 13,  4,  5,  5,  5, 13,  8,  8, 10, 11, 16, 14,  6, 10, 15,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 15, 10,  6, 14, 16, 11, 10,\n",
       "          8,  8, 13,  5,  5,  5,  4, 13,  5, 12, 14,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0, 19]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Yak-hbdx/Seq-Rev-TransfoRNA/commit/aff4c111f6ab9817ccf1a199f66e9246b92fa2ba', commit_message='Upload tokenizer', commit_description='', oid='aff4c111f6ab9817ccf1a199f66e9246b92fa2ba', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save tokenizer and push to hub\n",
    "tokenizer.push_to_hub(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing sequences for yak-hbdx/seq-rev-transforna model...\n",
      "\u001b[92mPASSED\n"
     ]
    }
   ],
   "source": [
    "#load model and tokenizer\n",
    "model = GeneEmbeddModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "tokenizer = RnaTokenizer.from_pretrained(model_name,model_name=model_name)\n",
    "output = tokenizer(['AAAGTCGGAGGTTCGAAGACGATCAGATAC','TTTTCGGAACTGAGGCCATGATTAAGAGGG'])\n",
    "gene_embedd, second_input_embedd, activations,attn_scores_first,attn_scores_second = model(output['input_ids'])\n",
    "#get the idx of the maximum value in the gene_embedd tensor at each row\n",
    "class_ids = torch.argmax(activations,dim=1).numpy()\n",
    "class_labels = model.convert_ids_to_labels(class_ids)\n",
    "#asset ['18S_bin-38', '18S_bin-33']\n",
    "assert class_labels == ['18S_bin-38', '18S_bin-33'], print('\\033[91m' + 'FAILED')\n",
    "print('\\033[92m' + 'PASSED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transforna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
