{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforna import GeneEmbeddModel,RnaTokenizer\n",
    "import torch\n",
    "model_name = 'Seq-Struct'\n",
    "model_path = f\"Yak-hbdx/{model_name}-TransfoRNA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq-Struct\n",
      "{'AA': 5, 'AC': 3, 'AG': 15, 'AT': 12, 'CA': 4, 'CC': 6, 'CG': 9, 'CT': 1, 'GA': 14, 'GC': 10, 'GG': 16, 'GT': 13, 'TA': 2, 'TC': 8, 'TG': 11, 'TT': 7, 'pad': 0, '((': 3, '(.': 4, ')(': 8, '))': 7, ').': 6, '.(': 2, '.)': 5, '..': 1}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m gene_embedd, second_input_embedd, activations,attn_scores_first,attn_scores_second \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m      9\u001b[0m                                 model(output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#get the idx of the maximum value in the gene_embedd tensor at each row\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m class_labels \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_ids_to_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#asset ['18S_bin-38', '18S_bin-33']\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m class_labels \u001b[38;5;241m==\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m18S_bin-38\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m18S_bin-33\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[91m\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFAILED\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/conda/envs/hbdx/envs/transforna/lib/python3.9/site-packages/transforna/src/model/model_components.py:415\u001b[0m, in \u001b[0;36mconvert_ids_to_labels\u001b[0;34m(self, class_ids)\u001b[0m\n\u001b[1;32m    404\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber of parameters: \u001b[39m\u001b[38;5;132;01m%e\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters()))\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m#NOTE: if novelty prediction is to be available through huggingface model hub, this method should be implemented\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m#def compute_novelty(self, embedds:torch.Tensor,query_seqs:List[str],num_neighbors:int):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m#    lev_dist = get_lev_dist(query_seqs,top_n_seqs)\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m#    return query_seqs,top_n_seqs,top_n_labels,distances,lev_dist\u001b[39;00m\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_ids_to_labels\u001b[39m(\u001b[38;5;28mself\u001b[39m, activations:torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    416\u001b[0m     class_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(activations,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmain_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_mappings\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mint\u001b[39m(c)] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m class_ids]\n",
      "File \u001b[0;32m~/conda/envs/hbdx/envs/transforna/lib/python3.9/site-packages/transforna/src/model/model_components.py:415\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    404\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber of parameters: \u001b[39m\u001b[38;5;132;01m%e\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters()))\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m#NOTE: if novelty prediction is to be available through huggingface model hub, this method should be implemented\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m#def compute_novelty(self, embedds:torch.Tensor,query_seqs:List[str],num_neighbors:int):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m#    lev_dist = get_lev_dist(query_seqs,top_n_seqs)\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m#    return query_seqs,top_n_seqs,top_n_labels,distances,lev_dist\u001b[39;00m\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_ids_to_labels\u001b[39m(\u001b[38;5;28mself\u001b[39m, activations:torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    416\u001b[0m     class_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(activations,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmain_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_mappings\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mint\u001b[39m(c)] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m class_ids]\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "#load model and tokenizer\n",
    "model = GeneEmbeddModel.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = RnaTokenizer.from_pretrained(model_path,model_name=model_name)\n",
    "output = tokenizer(['AAAGTCGGAGGTTCGAAGACGATCAGATAC','TTTTCGGAACTGAGGCCATGATTAAGAGGG'])\n",
    "\n",
    "gene_embedd, second_input_embedd, activations,attn_scores_first,attn_scores_second = \\\n",
    "                                model(output['input_ids'])\n",
    "#get the idx of the maximum value in the gene_embedd tensor at each row\n",
    "class_labels = model.convert_ids_to_labels(activations)\n",
    "#asset ['18S_bin-38', '18S_bin-33']\n",
    "assert class_labels == ['18S_bin-38', '18S_bin-33'], print('\\033[91m' + 'FAILED')\n",
    "print('\\033[92m' + 'PASSED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "api = huggingface_hub.HfApi()\n",
    "api.upload_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transforna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
